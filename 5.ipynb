{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "def build_gensim_w2v_model(model_path, iter_tokens, size, window, min_count):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    model_path : string\n",
    "        Path of Word2Vec model\n",
    "    iter_tokens : iterator\n",
    "        Iterator of documents, which are lists of words\n",
    "    \"\"\"\n",
    "    model = Word2Vec(\n",
    "        size=size,\n",
    "        window=window,\n",
    "        min_count=min_count,\n",
    "        workers=multiprocessing.cpu_count()\n",
    "    )\n",
    "    model.build_vocab(iter_tokens())\n",
    "    model.train(iter_tokens())\n",
    "    model.init_sims(replace=True)\n",
    "    model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec.load('latest-ja-word2vec-gensim-model/word2vec.gensim.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('カレーライス', 0.9314418435096741),\n",
       " ('焼きそば', 0.9272939562797546),\n",
       " ('おにぎり', 0.9142351746559143),\n",
       " ('お好み焼き', 0.908762514591217),\n",
       " ('天ぷら', 0.9079930186271667),\n",
       " ('焼き鳥', 0.906843364238739),\n",
       " ('ハンバーグ', 0.9052976369857788),\n",
       " ('寿司', 0.9030996561050415),\n",
       " ('豆腐', 0.9005953073501587),\n",
       " ('丼', 0.8975555300712585)]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=['カレー','うどん'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('警察官', 0.8157522678375244),\n",
       " ('下士官', 0.7801075577735901),\n",
       " ('拳銃', 0.7748473882675171),\n",
       " ('刑務官', 0.7705545425415039),\n",
       " ('銃', 0.7351149320602417),\n",
       " ('看守', 0.7313598394393921),\n",
       " ('将校', 0.7227283716201782),\n",
       " ('海上保安官', 0.7194071412086487),\n",
       " ('操縦士', 0.714685320854187),\n",
       " ('警官', 0.7088242769241333)]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=['公務員','ピストル'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('夜行', 0.5844853520393372),\n",
       " ('号', 0.5553199648857117),\n",
       " ('東松', 0.554681658744812),\n",
       " ('宗谷丸', 0.5325208902359009),\n",
       " ('海防艦', 0.5275475382804871),\n",
       " ('特別陸戦隊', 0.5265254974365234),\n",
       " ('11号', 0.5212676525115967),\n",
       " ('18号', 0.5175169706344604),\n",
       " ('13号', 0.5138446092605591),\n",
       " ('宇高連絡船', 0.5095405578613281)]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=['車'],negative = ['タイヤ'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('廃人', 0.6236408948898315),\n",
       " ('瀕死', 0.6161459684371948),\n",
       " ('黒い', 0.6008692979812622),\n",
       " ('ゾンビ', 0.6001749038696289),\n",
       " ('裸', 0.5953300595283508),\n",
       " ('白い', 0.5899269580841064),\n",
       " ('異形', 0.5870126485824585),\n",
       " ('炎', 0.5860205888748169),\n",
       " ('サソリ', 0.5854195356369019),\n",
       " ('血まみれ', 0.5840049982070923)]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=['人間'],negative = ['知識'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ニワトリ', 0.9043030738830566),\n",
       " ('ウサギ', 0.8948085308074951),\n",
       " ('アライグマ', 0.8850668668746948),\n",
       " ('ブタ', 0.8836382627487183),\n",
       " ('カエル', 0.8821595907211304),\n",
       " ('イノシシ', 0.8803962469100952),\n",
       " ('モルモット', 0.8797956109046936),\n",
       " ('キツネ', 0.8794952630996704),\n",
       " ('ハチ', 0.871435284614563),\n",
       " ('ネズミ', 0.8713341951370239)]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=['イヌ','ネコ'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 考察\n",
    "word2vecを実際に動かしてみた。カレーとラーメンを足してみたがカレーライスが一番の候補に挙がってしまった。カレーラーメンはもともと登録されていなかった単語だったため、出力しなかった。そのため登録されているカレーうどんを試しに、カレーとうどんを足してみたが上のほうになかった。原因として考えられるのは、カレーうどんはカレーとうどんをレシピ上では足したものではあるが今回使用したモデルの学習したデータセットでは、別々の文章の中にカレーとうどんが入っていたためであると考えられる。足し引きで容易に想像のつくものは大体その通りになったが想像できないものは、方向性が同じなものが候補として挙げられていた。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
